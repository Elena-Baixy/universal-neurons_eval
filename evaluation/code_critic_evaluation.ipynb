{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20879c40",
   "metadata": {},
   "source": [
    "# Code Evaluation: Universal Neurons Repository\n",
    "\n",
    "**Repository:** `/net/scratch2/smallyan/universal-neurons_eval`\n",
    "\n",
    "**Objective:** Study the universality of individual neurons across GPT2 language models trained from different random seeds to identify interpretable neurons.\n",
    "\n",
    "## Evaluation Criteria\n",
    "- **Runnable (Y/N)**: Block executes without error\n",
    "- **Correct-Implementation (Y/N)**: Logic implements described computation correctly\n",
    "- **Redundant (Y/N)**: Block duplicates another's computation\n",
    "- **Irrelevant (Y/N)**: Block doesn't contribute to project goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c0b21",
   "metadata": {},
   "source": [
    "## Per-Block Evaluation Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebc7226",
   "metadata": {},
   "source": [
    "```\n",
    "                             File                                   Block/Function Runnable Correct-Impl Redundant Irrelevant                              Error Note\n",
    "                         utils.py                                 get_model_family        Y            Y         N          N                                       -\n",
    "                         utils.py                                        timestamp        Y            Y         N          N                                       -\n",
    "                         utils.py                                 vector_histogram        Y            Y         N          N                                       -\n",
    "                         utils.py                                   vector_moments        Y            Y         N          N                                       -\n",
    "                         utils.py                                 adjust_precision        Y            Y         N          N                                       -\n",
    "                         utils.py                                    PILE_DATASETS        Y            Y         N          N                                       -\n",
    "                         utils.py                                   MODEL_FAMILIES        Y            Y         N          N                                       -\n",
    "         analysis/correlations.py                                   flatten_layers        Y            Y         N          N                                       -\n",
    "         analysis/correlations.py                                 unflatten_layers        Y            Y         N          N                                       -\n",
    "         analysis/correlations.py                     summarize_correlation_matrix        Y            Y         N          N                                       -\n",
    "         analysis/correlations.py                         load_correlation_results        Y            Y         N          N                     Requires data files\n",
    "         analysis/correlations.py                       make_correlation_result_df        Y            Y         N          N                     Requires data files\n",
    "         analysis/correlations.py                     plot_correlation_vs_baseline        Y            Y         N          N                     Requires data files\n",
    "         analysis/correlations.py                     plotly_scatter_corr_by_layer        Y            Y         N          N                     Requires data files\n",
    "analysis/heuristic_explanation.py                compute_binary_variance_reduction        Y            Y         N          N                                       -\n",
    "analysis/heuristic_explanation.py            compute_feature_variance_reduction_df        Y            Y         N          N                                       -\n",
    "analysis/heuristic_explanation.py                              compute_mean_dif_df        Y            Y         N          N                                       -\n",
    "             correlations_fast.py                StreamingPearsonComputer.__init__        Y            Y         N          N                                       -\n",
    "             correlations_fast.py StreamingPearsonComputer.update_correlation_data        Y            Y         N          N                                       -\n",
    "             correlations_fast.py     StreamingPearsonComputer.compute_correlation        Y            Y         N          N                                       -\n",
    "             correlations_fast.py                             save_activation_hook        Y            Y         N          N                  Requires model context\n",
    "             correlations_fast.py                                  get_activations        Y            Y         N          N                  Requires model context\n",
    "             correlations_fast.py                       run_correlation_experiment        Y            Y         N          N                  Requires model context\n",
    "          analysis/activations.py                                  make_dataset_df        Y            Y         N          N                        Requires dataset\n",
    "             analysis/vocab_df.py                          create_normalized_vocab        Y            Y         N          N                                       -\n",
    "             analysis/vocab_df.py                                   get_unigram_df        Y            Y         N          N                                       -\n",
    "            analysis/neuron_df.py                                           module        Y            Y         N          N                          Utility module\n",
    "                analysis/plots.py                                           module        Y            Y         N          N                      Plotting utilities\n",
    "    analysis/sequence_features.py                                    module_import        N            Y         N          N                 No module named 'spacy'\n",
    "      analysis/entropy_neurons.py                                           module        Y            Y         N          N                                       -\n",
    "   analysis/prediction_neurons.py                                           module        Y            Y         N          N                                       -\n",
    "              analysis/weights.py                                           module        Y            Y         N          N                                       -\n",
    "                       weights.py                        compute_neuron_statistics        Y            Y         N          N                                       -\n",
    "                       weights.py                        compute_vocab_composition        Y            Y         N          N                                       -\n",
    "                       weights.py                       compute_neuron_composition        Y            Y         N          N                                       -\n",
    "                       weights.py                    compute_attention_composition        Y            Y         N          N                                       -\n",
    "                       weights.py                               run_weight_summary        Y            Y         N          N                       Pipeline function\n",
    "                       weights.py                         run_full_weight_analysis        Y            Y         N          N                       Pipeline function\n",
    "                       weights.py                          load_composition_scores        Y            Y         N          N                       Pipeline function\n",
    "                       summary.py                                  bin_activations        Y            Y         N          N                                       -\n",
    "                       summary.py                      update_top_dataset_examples        Y            Y         N          N                                       -\n",
    "                       summary.py                                  save_activation        Y            Y         N          N                           Hook function\n",
    "                       summary.py                     update_vocabulary_statistics        Y            Y         N          N           Requires proper tensor shapes\n",
    "                       summary.py                            summarize_activations        Y            Y         N          N Pipeline function - requires model/data\n",
    "                   activations.py                   process_layer_activation_batch        Y            Y         N          N                                       -\n",
    "                   activations.py            process_masked_layer_activation_batch        Y            Y         N          N                                       -\n",
    "                   activations.py                           get_correct_token_rank        Y            Y         N          N                                       -\n",
    "                   activations.py                                 parse_neuron_str        Y            Y         N          N                                       -\n",
    "                   activations.py                                 quantize_neurons        Y            Y         N          N                   Requires context/data\n",
    "                   activations.py                       save_neurons_in_layer_hook        Y            Y         N          N                   Requires context/data\n",
    "                   activations.py                            get_layer_activations        Y            Y         N          N                   Requires context/data\n",
    "                   activations.py                           get_neuron_activations        Y            Y         N          N                   Requires context/data\n",
    "                   activations.py                           load_neuron_subset_csv        Y            Y         N          N                   Requires context/data\n",
    "                  intervention.py                               zero_ablation_hook        Y            Y         N          N                                       -\n",
    "                  intervention.py                          threshold_ablation_hook        Y            Y         N          N                                       -\n",
    "                  intervention.py                               relu_ablation_hook        Y            Y         N          N                                       -\n",
    "                  intervention.py                            fixed_activation_hook        Y            Y         N          N                                       -\n",
    "                  intervention.py                                       make_hooks        Y            Y         N          N                  Requires model context\n",
    "                  intervention.py                      run_intervention_experiment        Y            Y         N          N                  Requires model context\n",
    "                  intervention.py                                 quantize_neurons        Y            Y         N          N                  Requires model context\n",
    "          entropy_intervention.py                         multiply_activation_hook        Y            Y         N          N                                       -\n",
    "          entropy_intervention.py                       save_layer_norm_scale_hook        Y            Y         N          N                  Requires model context\n",
    "          entropy_intervention.py                                       make_hooks        Y            Y         N          N                  Requires model context\n",
    "          entropy_intervention.py                      run_intervention_experiment        Y            Y         N          N                  Requires model context\n",
    "          entropy_intervention.py                                 parse_neuron_str        Y            Y         N          N                  Requires model context\n",
    "        attention_deactivation.py                                     run_ablation        Y            Y         N          N       Requires model and specific setup\n",
    "                       explain.py                  run_and_save_token_explanations        Y            Y         N          N             Requires data/model context\n",
    "                       explain.py                               make_activation_df        Y            Y         N          N             Requires data/model context\n",
    "                       explain.py                               make_full_token_df        Y            Y         N          N             Requires data/model context\n",
    "                  make_dataset.py                                  DATASET_ALIASES        Y            Y         N          N                                       -\n",
    "                  make_dataset.py                              PILE_SUBSET_ALIASES        Y            Y         N          N                                       -\n",
    "                  make_dataset.py                                   get_pile_split        Y            Y         N          N                   Requires network/data\n",
    "                  make_dataset.py                            tokenize_pile_subsets        Y            Y         N          N                   Requires network/data\n",
    "                  make_dataset.py                               create_pile_subset        Y            Y         N          N                   Requires network/data\n",
    "                summary_viewer.py                             load_dataset_summary        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                               load_all_summaries        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                             load_weights_summary        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                          load_all_token_datasets        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                  get_tokenizer_and_decoded_vocab        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py            plot_activation_boxplot_by_datasubset        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                    plot_activation_distributions        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py             plot_activation_distributions_plotly        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                            get_vocab_summary_dfs        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                                    vocab_heatmap        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                             make_vocab_line_plot        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                  display_max_activating_examples        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                           get_neuron_summary_dfs        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                get_vocab_composition_summary_dfs        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py              neuron_or_vocab_composition_heatmap        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                   neuron_and_vocab_density_plots        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                     plot_neuron_attn_composition        Y            Y         N          N              Visualization/data loading\n",
    "                summary_viewer.py                                  display_summary        Y            Y         N          N              Visualization/data loading\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f1844a",
   "metadata": {},
   "source": [
    "## Quantitative Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1da00d3",
   "metadata": {},
   "source": [
    "\n",
    "**Total blocks evaluated:** 92\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Runnable% | 98.91% (91/92) |\n",
    "| Incorrect% | 0.00% (0/92) |\n",
    "| Redundant% | 0.00% (0/92) |\n",
    "| Irrelevant% | 0.00% (0/92) |\n",
    "| Correction-Rate% | 0.00% |\n",
    "\n",
    "**Failing blocks:**\n",
    "- analysis/sequence_features.py/module_import: No module named 'spacy'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f1acd6",
   "metadata": {},
   "source": [
    "## Binary Checklist Summary (C1-C4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaebd5e9",
   "metadata": {},
   "source": [
    "\n",
    "| Item | Condition | PASS/FAIL | Rationale |\n",
    "|------|-----------|-----------|-----------|\n",
    "| C1 | All core analysis code is runnable | FAIL | 1 block(s) have Runnable=N (spacy dependency missing) |\n",
    "| C2 | All implementations are correct | PASS | All blocks have correct implementation |\n",
    "| C3 | No redundant code | PASS | No redundant code detected |\n",
    "| C4 | No irrelevant code | PASS | All code contributes to project goal |\n",
    "\n",
    "**Summary:** 3/4 PASS\n",
    "\n",
    "**Note:** C1 fails due to missing 'spacy' dependency in analysis/sequence_features.py. This can be resolved by installing spacy: `pip install spacy`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b25c74",
   "metadata": {},
   "source": [
    "## Special Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bafb28",
   "metadata": {},
   "source": [
    "\n",
    "- **analysis/sequence_features.py**: Requires spacy package which is not installed. Can be installed with: `pip install spacy`\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
