{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b62651db",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: /home/smallyan/eval_agent\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/smallyan/eval_agent')\n",
    "print(\"Working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce742a46",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results Summary:\n",
      "============================================================\n",
      "RP1: PASS\n",
      "RP2: PASS\n",
      "RP3: FAIL\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Based on my analysis of the documentation, I'll now create the evaluation files\n",
    "\n",
    "# Store the evaluation results\n",
    "evaluation_results = {\n",
    "    \"RP1\": {\n",
    "        \"verdict\": \"PASS\",\n",
    "        \"analysis\": \"\"\"\n",
    "The documentation provides sufficient detail for the core experiment:\n",
    "\n",
    "DOCUMENTED PROCEDURES:\n",
    "1. Correlation Computation (Section 4.1, A.2):\n",
    "   - Pearson correlation formula (Eq. 2)\n",
    "   - Excess correlation formula (Eq. 3)\n",
    "   - Baseline correlation with random rotation\n",
    "   - Dataset: 100M tokens from Pile test set\n",
    "   - Context length: 512 tokens\n",
    "   - Efficient streaming algorithm with formulas\n",
    "\n",
    "2. Neuron Analysis (Section 4.2):\n",
    "   - Statistics: mean, skew, kurtosis of pre-activation\n",
    "   - Activation sparsity definition\n",
    "   - Weight metrics specified\n",
    "\n",
    "3. Mathematical Foundations:\n",
    "   - MLP formulation (Eq. 1)\n",
    "   - Reduction in variance formula (Eq. 4)\n",
    "   - LayerNorm formula (Eq. 5)\n",
    "   - Heuristic score formula for attention deactivation\n",
    "\n",
    "MINOR GAPS:\n",
    "- Complete list of automated tests not provided\n",
    "- Topic model details underspecified\n",
    "- Intervention procedure parameters implicit\n",
    "\n",
    "The core methodology for identifying universal neurons is reconstructable.\n",
    "\"\"\"\n",
    "    },\n",
    "    \"RP2\": {\n",
    "        \"verdict\": \"PASS\",\n",
    "        \"analysis\": \"\"\"\n",
    "The documentation explicitly specifies required resources:\n",
    "\n",
    "MODELS:\n",
    "- GPT2 models: stanford-crfm/arwen-gpt2-medium-x21, stanford-crfm/alias-gpt2-small-x21\n",
    "- Pythia: EleutherAI/pythia-160m\n",
    "- Model hyperparameters in Table 1 (layers, heads, dmodel, etc.)\n",
    "\n",
    "DATASETS:\n",
    "- Pile test set, 100 million tokens\n",
    "- Context length: 512 tokens\n",
    "- Reference: Gao et al., 2020\n",
    "\n",
    "DEPENDENCIES:\n",
    "- TransformerLens library (Nanda, 2022)\n",
    "- spaCy package (Honnibal et al., 2020)\n",
    "- Code available: github.com/wesg52/universal-neurons\n",
    "\n",
    "COMPUTE:\n",
    "- MIT Supercloud mentioned\n",
    "\n",
    "All critical resources are publicly available and explicitly identified.\n",
    "\"\"\"\n",
    "    },\n",
    "    \"RP3\": {\n",
    "        \"verdict\": \"FAIL\",\n",
    "        \"analysis\": \"\"\"\n",
    "The documentation does NOT adequately address sources of randomness:\n",
    "\n",
    "IDENTIFIED SOURCES OF VARIABILITY:\n",
    "1. Random initialization of Gaussian matrix R for baseline correlation\n",
    "2. Random subset selection for path ablation experiments\n",
    "3. Five different random seeds for model training (acknowledged)\n",
    "\n",
    "WHAT IS MISSING:\n",
    "- No random seeds specified for reproducibility\n",
    "- No explicit handling of sampling variability\n",
    "- No confidence intervals or variance estimates for key metrics\n",
    "- The threshold ϱ > 0.5 is acknowledged as arbitrary\n",
    "- No specification of how many runs/samples for interventions\n",
    "\n",
    "The paper studies variability across model seeds as its main research \n",
    "question, but does not provide seeds or procedures to ensure exact \n",
    "reproducibility of the analysis itself.\n",
    "\n",
    "While some consistency is shown (Figure 2b, 6c), the specific values \n",
    "reported (1.23%, 4.16% universal neurons) would likely vary without \n",
    "exact seeds and sampling procedures.\n",
    "\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Evaluation Results Summary:\")\n",
    "print(\"=\"*60)\n",
    "for rp, result in evaluation_results.items():\n",
    "    print(f\"{rp}: {result['verdict']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24874817",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: /net/scratch2/smallyan/universal-neurons_eval/doc_only_evaluation/replication_evaluation.md\n",
      "File size: 6307 bytes\n"
     ]
    }
   ],
   "source": [
    "# Create the output directory and files\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "output_dir = '/net/scratch2/smallyan/universal-neurons_eval/doc_only_evaluation'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create the markdown evaluation file\n",
    "md_content = \"\"\"# Replication Evaluation - Universal Neurons in GPT2 Language Models\n",
    "\n",
    "## Evaluation Overview\n",
    "\n",
    "This evaluation assesses whether the documentation for \"Universal Neurons in GPT2 Language Models\" (Gurnee et al., 2024) provides sufficient information for an independent researcher to reproduce the experiment and its results without access to the original code.\n",
    "\n",
    "**Documentation Source:** `/net/scratch2/smallyan/universal-neurons_eval/documentation.pdf`\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation Notes\n",
    "\n",
    "### RP1: Implementation Reconstructability\n",
    "\n",
    "**Assessment: PASS**\n",
    "\n",
    "The documentation provides sufficient methodological detail for reconstructing the core experiment:\n",
    "\n",
    "**Documented Procedures:**\n",
    "\n",
    "1. **Correlation Computation (Section 4.1, Appendix A.2):**\n",
    "   - Pearson correlation formula explicitly given (Equation 2)\n",
    "   - Excess correlation formula explicitly given (Equation 3)\n",
    "   - Baseline correlation methodology: correlation with random rotation of neuron basis\n",
    "   - Dataset specification: 100 million tokens from Pile test set\n",
    "   - Context length: 512 tokens\n",
    "   - Excluded tokens: padding, BOS, newline tokens\n",
    "   - Efficient streaming algorithm described with explicit formulas\n",
    "\n",
    "2. **Neuron Analysis (Section 4.2):**\n",
    "   - Activation statistics: mean, skew, kurtosis of pre-activation distribution\n",
    "   - Activation sparsity: fraction of activations > 0\n",
    "   - Weight metrics: input bias, cos(win, wout), weight decay penalty, kurtosis of cos(wout, WU)\n",
    "\n",
    "3. **Mathematical Foundations:**\n",
    "   - MLP layer formulation (Equation 1)\n",
    "   - Reduction in variance formula for automated tests (Equation 4)\n",
    "   - LayerNorm formula (Equation 5)\n",
    "   - Heuristic score formula for attention deactivation\n",
    "\n",
    "4. **Weight Preprocessing (Appendix A.1):**\n",
    "   - Layer norm folding procedure\n",
    "   - Weight centering procedures\n",
    "   - Unembedding centering\n",
    "\n",
    "**Minor Gaps:**\n",
    "- Complete list of automated tests not enumerated (only \"several hundred\" mentioned)\n",
    "- Topic model details underspecified\n",
    "- Intervention procedure parameters implicit\n",
    "\n",
    "**Conclusion:** The core methodology for identifying universal neurons via activation correlations is sufficiently detailed for reconstruction.\n",
    "\n",
    "---\n",
    "\n",
    "### RP2: Environment and Resource Specification\n",
    "\n",
    "**Assessment: PASS**\n",
    "\n",
    "The documentation explicitly specifies all required resources:\n",
    "\n",
    "**Models:**\n",
    "- GPT2-medium: `stanford-crfm/arwen-gpt2-medium-x21`\n",
    "- GPT2-small: `stanford-crfm/alias-gpt2-small-x21`\n",
    "- Pythia-160m: `EleutherAI/pythia-160m`\n",
    "- Model hyperparameters detailed in Table 1 (layers, heads, dmodel, dvocab, dMLP, parameters, context, activation function, positional embeddings, precision, dataset, dropout)\n",
    "\n",
    "**Datasets:**\n",
    "- Pile test set (Gao et al., 2020)\n",
    "- 100 million tokens\n",
    "- Context length: 512 tokens\n",
    "- Training data: OpenWebText (GPT2), Pile (Pythia)\n",
    "\n",
    "**Dependencies:**\n",
    "- TransformerLens library (Nanda, 2022)\n",
    "- spaCy package (Honnibal et al., 2020)\n",
    "\n",
    "**Code Availability:**\n",
    "- GitHub repository: `https://github.com/wesg52/universal-neurons`\n",
    "- Explicitly stated: \"All of our code and data is available\"\n",
    "\n",
    "**Compute Resources:**\n",
    "- MIT Supercloud (Reuther et al., 2018)\n",
    "\n",
    "**Conclusion:** All critical resources are publicly available and explicitly identified.\n",
    "\n",
    "---\n",
    "\n",
    "### RP3: Determinism and Stability\n",
    "\n",
    "**Assessment: FAIL**\n",
    "\n",
    "The documentation does NOT adequately address sources of randomness and variability:\n",
    "\n",
    "**Identified Sources of Variability:**\n",
    "1. Random initialization of Gaussian matrix R for baseline correlation computation\n",
    "2. Random subset selection for path ablation experiments (\"random subset of tokens in the second half of the context\")\n",
    "3. Five different random seeds for model training (the main focus of the study)\n",
    "\n",
    "**Missing Information:**\n",
    "- No random seeds specified for the analysis procedures\n",
    "- No explicit handling of sampling variability\n",
    "- No confidence intervals or variance estimates for key metrics (e.g., 1.23%, 4.16% universal neurons)\n",
    "- The threshold ϱ > 0.5 is acknowledged as arbitrary with no sensitivity analysis\n",
    "- No specification of how many runs/samples for intervention experiments\n",
    "- No explicit discussion of reproducibility guarantees\n",
    "\n",
    "**Stability Claims Without Support:**\n",
    "- Figure 2b shows consistency across models but without error bars\n",
    "- Figure 6c shows shaded ranges across seeds but methodology not detailed\n",
    "- The finding that \"1.23% and 1.26%\" of neurons are universal in different models suggests consistency but exact reproducibility procedures are absent\n",
    "\n",
    "**Conclusion:** While the paper studies variability across model seeds as its primary research question, it does not provide sufficient detail to ensure exact reproducibility of the analysis itself. The specific quantitative claims would likely vary without exact seeds and sampling procedures.\n",
    "\n",
    "---\n",
    "\n",
    "## Binary Checklist Table\n",
    "\n",
    "| Criterion | Description | Verdict |\n",
    "|-----------|-------------|---------|\n",
    "| **RP1** | Implementation Reconstructability | **PASS** |\n",
    "| **RP2** | Environment and Resource Specification | **PASS** |\n",
    "| **RP3** | Determinism and Stability | **FAIL** |\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**Overall Replicability Assessment: PARTIAL**\n",
    "\n",
    "The documentation for \"Universal Neurons in GPT2 Language Models\" provides strong methodological detail for the core experiment. The mathematical formulations, model specifications, and dataset descriptions are sufficiently detailed for an independent researcher to implement the correlation-based universal neuron identification procedure.\n",
    "\n",
    "However, the documentation fails to address determinism and stability adequately. Sources of randomness in the analysis (random baseline matrices, random sampling for ablation studies) are not controlled through specified seeds, and no variance estimates or confidence intervals are provided for key quantitative findings.\n",
    "\n",
    "**What can be replicated:**\n",
    "- The methodology for computing neuron correlations across models\n",
    "- The identification of neurons with high excess correlation\n",
    "- The general patterns in neuron families and functional roles\n",
    "\n",
    "**What may not be exactly reproduced:**\n",
    "- Specific percentage values (1.23%, 4.16% universal neurons)\n",
    "- Exact lists of universal neurons\n",
    "- Quantitative results from causal interventions\n",
    "\n",
    "The availability of code at `github.com/wesg52/universal-neurons` partially mitigates these concerns, but from a documentation-only perspective, exact replication is not guaranteed.\n",
    "\"\"\"\n",
    "\n",
    "# Write the markdown file\n",
    "md_path = os.path.join(output_dir, 'replication_evaluation.md')\n",
    "with open(md_path, 'w') as f:\n",
    "    f.write(md_content)\n",
    "\n",
    "print(f\"Created: {md_path}\")\n",
    "print(f\"File size: {os.path.getsize(md_path)} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37db4d68",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: /net/scratch2/smallyan/universal-neurons_eval/doc_only_evaluation/self_replication_evaluation.json\n",
      "File size: 2318 bytes\n",
      "\n",
      "JSON Content:\n",
      "{\n",
      "  \"Checklist\": {\n",
      "    \"RP1_ImplementationReconstructability\": \"PASS\",\n",
      "    \"RP2_EnvironmentReproducibility\": \"PASS\",\n",
      "    \"RP3_DeterminismAndStability\": \"FAIL\"\n",
      "  },\n",
      "  \"Rationale\": {\n",
      "    \"RP1_ImplementationReconstructability\": \"The documentation provides sufficient methodological detail for reconstructing the core experiment. Key elements include: (1) Pearson correlation formula (Eq. 2) and excess correlation formula (Eq. 3) for identifying universal neurons; (2) efficient streaming algorithm for computing correlations over 100M tokens; (3) dataset specification (Pile test set, 512 token context); (4) neuron analysis metrics (activation statistics, weight metrics); (5) mathematical foundations for MLP layers, LayerNorm, and automated tests (Eqs. 1, 4, 5); (6) weight preprocessing procedures in Appendix A.1. Minor gaps exist in secondary analyses (complete test list, intervention parameters) but the core methodology is reconstructable.\",\n",
      "    \"RP2_EnvironmentReproducibility\": \"All critical resources are explicitly identified and publicly available: (1) Models specified with exact HuggingFace identifiers (stanford-crfm/arwen-gpt2-medium-x21, stanford-crfm/alias-gpt2-small-x21, EleutherAI/pythia-160m); (2) model hyperparameters detailed in Table 1; (3) dataset specified as Pile test set with 100M tokens and 512 context length; (4) key dependencies identified (TransformerLens, spaCy); (5) code and data available at github.com/wesg52/universal-neurons; (6) compute resources (MIT Supercloud) mentioned.\",\n",
      "    \"RP3_DeterminismAndStability\": \"The documentation fails to adequately address sources of randomness and variability. Critical gaps include: (1) No random seeds specified for the random Gaussian matrix R used in baseline correlation computation; (2) No seeds for random subset selection in path ablation experiments; (3) No confidence intervals or variance estimates for key metrics (e.g., 1.23%, 4.16% universal neurons); (4) The threshold \\u03f1 > 0.5 is acknowledged as arbitrary with no sensitivity analysis; (5) No specification of number of runs/samples for intervention experiments; (6) No explicit reproducibility guarantees. While the paper studies variability across model seeds as its primary research question, it does not ensure exact reproducibility of the analysis itself.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create the JSON summary file\n",
    "\n",
    "json_content = {\n",
    "    \"Checklist\": {\n",
    "        \"RP1_ImplementationReconstructability\": \"PASS\",\n",
    "        \"RP2_EnvironmentReproducibility\": \"PASS\",\n",
    "        \"RP3_DeterminismAndStability\": \"FAIL\"\n",
    "    },\n",
    "    \"Rationale\": {\n",
    "        \"RP1_ImplementationReconstructability\": \"The documentation provides sufficient methodological detail for reconstructing the core experiment. Key elements include: (1) Pearson correlation formula (Eq. 2) and excess correlation formula (Eq. 3) for identifying universal neurons; (2) efficient streaming algorithm for computing correlations over 100M tokens; (3) dataset specification (Pile test set, 512 token context); (4) neuron analysis metrics (activation statistics, weight metrics); (5) mathematical foundations for MLP layers, LayerNorm, and automated tests (Eqs. 1, 4, 5); (6) weight preprocessing procedures in Appendix A.1. Minor gaps exist in secondary analyses (complete test list, intervention parameters) but the core methodology is reconstructable.\",\n",
    "        \n",
    "        \"RP2_EnvironmentReproducibility\": \"All critical resources are explicitly identified and publicly available: (1) Models specified with exact HuggingFace identifiers (stanford-crfm/arwen-gpt2-medium-x21, stanford-crfm/alias-gpt2-small-x21, EleutherAI/pythia-160m); (2) model hyperparameters detailed in Table 1; (3) dataset specified as Pile test set with 100M tokens and 512 context length; (4) key dependencies identified (TransformerLens, spaCy); (5) code and data available at github.com/wesg52/universal-neurons; (6) compute resources (MIT Supercloud) mentioned.\",\n",
    "        \n",
    "        \"RP3_DeterminismAndStability\": \"The documentation fails to adequately address sources of randomness and variability. Critical gaps include: (1) No random seeds specified for the random Gaussian matrix R used in baseline correlation computation; (2) No seeds for random subset selection in path ablation experiments; (3) No confidence intervals or variance estimates for key metrics (e.g., 1.23%, 4.16% universal neurons); (4) The threshold ϱ > 0.5 is acknowledged as arbitrary with no sensitivity analysis; (5) No specification of number of runs/samples for intervention experiments; (6) No explicit reproducibility guarantees. While the paper studies variability across model seeds as its primary research question, it does not ensure exact reproducibility of the analysis itself.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the JSON file\n",
    "json_path = os.path.join(output_dir, 'self_replication_evaluation.json')\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(json_content, f, indent=2)\n",
    "\n",
    "print(f\"Created: {json_path}\")\n",
    "print(f\"File size: {os.path.getsize(json_path)} bytes\")\n",
    "\n",
    "# Display the JSON content\n",
    "print(\"\\nJSON Content:\")\n",
    "print(json.dumps(json_content, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4861af71",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in output directory:\n",
      "  self_matching.ipynb: 20999 bytes\n",
      "  consistency_evaluation.json: 3092 bytes\n",
      "  replication_evaluation.md: 6307 bytes\n",
      "  generalization_eval_summary.json: 1764 bytes\n",
      "  code_critic_evaluation.ipynb: 127502 bytes\n",
      "  code_critic_summary.json: 1289 bytes\n",
      "  generalization_eval.ipynb: 114167 bytes\n",
      "  self_replication_evaluation.json: 2318 bytes\n",
      "\n",
      "============================================================\n",
      "Verification: replication_evaluation.md (first 1000 chars)\n",
      "============================================================\n",
      "# Replication Evaluation - Universal Neurons in GPT2 Language Models\n",
      "\n",
      "## Evaluation Overview\n",
      "\n",
      "This evaluation assesses whether the documentation for \"Universal Neurons in GPT2 Language Models\" (Gurnee et al., 2024) provides sufficient information for an independent researcher to reproduce the experiment and its results without access to the original code.\n",
      "\n",
      "**Documentation Source:** `/net/scratch2/smallyan/universal-neurons_eval/documentation.pdf`\n",
      "\n",
      "---\n",
      "\n",
      "## Evaluation Notes\n",
      "\n",
      "### RP1: Implementation Reconstructability\n",
      "\n",
      "**Assessment: PASS**\n",
      "\n",
      "The documentation provides sufficient methodological detail for reconstructing the core experiment:\n",
      "\n",
      "**Documented Procedures:**\n",
      "\n",
      "1. **Correlation Computation (Section 4.1, Appendix A.2):**\n",
      "   - Pearson correlation formula explicitly given (Equation 2)\n",
      "   - Excess correlation formula explicitly given (Equation 3)\n",
      "   - Baseline correlation methodology: correlation with random rotation of neuron basis\n",
      "   - Dataset specification: 100 million tokens from Pi\n",
      "\n",
      "============================================================\n",
      "Verification: self_replication_evaluation.json\n",
      "============================================================\n",
      "{\n",
      "  \"Checklist\": {\n",
      "    \"RP1_ImplementationReconstructability\": \"PASS\",\n",
      "    \"RP2_EnvironmentReproducibility\": \"PASS\",\n",
      "    \"RP3_DeterminismAndStability\": \"FAIL\"\n",
      "  },\n",
      "  \"Rationale\": {\n",
      "    \"RP1_ImplementationReconstructability\": \"The documentation provides sufficient methodological detail for reconstructing the core experiment. Key elements include: (1) Pearson correlation formula (Eq. 2) and excess correlation formula (Eq. 3) for identifying universal neurons; (2) efficient streaming algorithm for computing correlations over 100M tokens; (3) dataset specification (Pile test set, 512 token context); (4) neuron analysis metrics (activation statistics, weight metrics); (5) mathematical foundations for MLP layers, LayerNorm, and automated tests (Eqs. 1, 4, 5); (6) weight preprocessing procedures in Appendix A.1. Minor gaps exist in secondary analyses (complete test list, intervention parameters) but the core methodology is reconstructable.\",\n",
      "    \"RP2_EnvironmentReproducibility\": \"All critical resources are explicitly identified and publicly available: (1) Models specified with exact HuggingFace identifiers (stanford-crfm/arwen-gpt2-medium-x21, stanford-crfm/alias-gpt2-small-x21, EleutherAI/pythia-160m); (2) model hyperparameters detailed in Table 1; (3) dataset specified as Pile test set with 100M tokens and 512 context length; (4) key dependencies identified (TransformerLens, spaCy); (5) code and data available at github.com/wesg52/universal-neurons; (6) compute resources (MIT Supercloud) mentioned.\",\n",
      "    \"RP3_DeterminismAndStability\": \"The documentation fails to adequately address sources of randomness and variability. Critical gaps include: (1) No random seeds specified for the random Gaussian matrix R used in baseline correlation computation; (2) No seeds for random subset selection in path ablation experiments; (3) No confidence intervals or variance estimates for key metrics (e.g., 1.23%, 4.16% universal neurons); (4) The threshold \\u03f1 > 0.5 is acknowledged as arbitrary with no sensitivity analysis; (5) No specification of number of runs/samples for intervention experiments; (6) No explicit reproducibility guarantees. While the paper studies variability across model seeds as its primary research question, it does not ensure exact reproducibility of the analysis itself.\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Verify the files were created correctly\n",
    "import os\n",
    "\n",
    "output_dir = '/net/scratch2/smallyan/universal-neurons_eval/doc_only_evaluation'\n",
    "\n",
    "print(\"Files in output directory:\")\n",
    "for f in os.listdir(output_dir):\n",
    "    filepath = os.path.join(output_dir, f)\n",
    "    print(f\"  {f}: {os.path.getsize(filepath)} bytes\")\n",
    "\n",
    "# Verify content of files\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Verification: replication_evaluation.md (first 1000 chars)\")\n",
    "print(\"=\"*60)\n",
    "with open(os.path.join(output_dir, 'replication_evaluation.md'), 'r') as f:\n",
    "    print(f.read()[:1000])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Verification: self_replication_evaluation.json\")\n",
    "print(\"=\"*60)\n",
    "with open(os.path.join(output_dir, 'self_replication_evaluation.json'), 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0f30e7",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "REPLICATION EVALUATION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "TASK: Replication Evaluation for Universal Neurons in GPT2 Language Models\n",
      "DOCUMENTATION: /net/scratch2/smallyan/universal-neurons_eval/documentation.pdf\n",
      "\n",
      "EVALUATION RESULTS:\n",
      "┌──────────────────────────────────────────┬─────────┐\n",
      "│ Criterion                                │ Verdict │\n",
      "├──────────────────────────────────────────┼─────────┤\n",
      "│ RP1: Implementation Reconstructability   │ PASS    │\n",
      "│ RP2: Environment and Resource Spec       │ PASS    │\n",
      "│ RP3: Determinism and Stability           │ FAIL    │\n",
      "└──────────────────────────────────────────┴─────────┘\n",
      "\n",
      "OUTPUT FILES:\n",
      "1. /net/scratch2/smallyan/universal-neurons_eval/doc_only_evaluation/replication_evaluation.md\n",
      "2. /net/scratch2/smallyan/universal-neurons_eval/doc_only_evaluation/self_replication_evaluation.json\n",
      "\n",
      "SUMMARY:\n",
      "- The documentation provides good methodological detail (RP1 PASS)\n",
      "- All required resources are explicitly specified (RP2 PASS)  \n",
      "- Sources of randomness are not adequately controlled (RP3 FAIL)\n",
      "\n",
      "The core experiment methodology is replicable, but exact numerical results\n",
      "may not be reproducible without additional seed specifications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"REPLICATION EVALUATION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "TASK: Replication Evaluation for Universal Neurons in GPT2 Language Models\n",
    "DOCUMENTATION: /net/scratch2/smallyan/universal-neurons_eval/documentation.pdf\n",
    "\n",
    "EVALUATION RESULTS:\n",
    "┌──────────────────────────────────────────┬─────────┐\n",
    "│ Criterion                                │ Verdict │\n",
    "├──────────────────────────────────────────┼─────────┤\n",
    "│ RP1: Implementation Reconstructability   │ PASS    │\n",
    "│ RP2: Environment and Resource Spec       │ PASS    │\n",
    "│ RP3: Determinism and Stability           │ FAIL    │\n",
    "└──────────────────────────────────────────┴─────────┘\n",
    "\n",
    "OUTPUT FILES:\n",
    "1. /net/scratch2/smallyan/universal-neurons_eval/doc_only_evaluation/replication_evaluation.md\n",
    "2. /net/scratch2/smallyan/universal-neurons_eval/doc_only_evaluation/self_replication_evaluation.json\n",
    "\n",
    "SUMMARY:\n",
    "- The documentation provides good methodological detail (RP1 PASS)\n",
    "- All required resources are explicitly specified (RP2 PASS)  \n",
    "- Sources of randomness are not adequately controlled (RP3 FAIL)\n",
    "\n",
    "The core experiment methodology is replicable, but exact numerical results\n",
    "may not be reproducible without additional seed specifications.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scribe: 2026-01-15-00-19_ReplicationEval2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
