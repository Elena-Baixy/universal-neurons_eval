{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "737d5ec4",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available. Device: NVIDIA H200 NVL\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/smallyan/eval_agent')\n",
    "\n",
    "# Check for GPU availability\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA available. Device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511ea8a1",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NO-EXECUTION CODE EVALUATION FOR CIRCUIT ANALYSIS\n",
      "Repository: /net/scratch2/smallyan/universal-neurons_eval\n",
      "================================================================================\n",
      "\n",
      "This evaluation analyzes all Python scripts and modules in the repository by\n",
      "STATIC INSPECTION ONLY (no code execution for verification).\n",
      "\n",
      "Files evaluated:\n",
      "- Main scripts: correlations_fast.py, correlations.py, summary.py, weights.py,\n",
      "  activations.py, explain.py, intervention.py, entropy_intervention.py,\n",
      "  attention_deactivation.py, attention_deactivation_qpos.py, utils.py, make_dataset.py\n",
      "- Analysis modules: analysis/*.py (11 files)\n",
      "- Paper notebooks: paper_notebooks/*.ipynb (12 notebooks)\n",
      "\n",
      "Evaluation Criteria:\n",
      "1. Runnable (Y/N): Syntactically valid, required imports available, no runtime blockers\n",
      "2. Correct-Implementation (Y/N): Logic implements described computation correctly\n",
      "3. Redundant (Y/N): Block duplicates another block's computation\n",
      "4. Irrelevant (Y/N): Block does not contribute to project goal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NO-EXECUTION CODE EVALUATION FOR CIRCUIT ANALYSIS\")\n",
    "print(\"Repository: /net/scratch2/smallyan/universal-neurons_eval\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"This evaluation analyzes all Python scripts and modules in the repository by\")\n",
    "print(\"STATIC INSPECTION ONLY (no code execution for verification).\")\n",
    "print()\n",
    "print(\"Files evaluated:\")\n",
    "print(\"- Main scripts: correlations_fast.py, correlations.py, summary.py, weights.py,\")\n",
    "print(\"  activations.py, explain.py, intervention.py, entropy_intervention.py,\")\n",
    "print(\"  attention_deactivation.py, attention_deactivation_qpos.py, utils.py, make_dataset.py\")\n",
    "print(\"- Analysis modules: analysis/*.py (11 files)\")\n",
    "print(\"- Paper notebooks: paper_notebooks/*.ipynb (12 notebooks)\")\n",
    "print()\n",
    "print(\"Evaluation Criteria:\")\n",
    "print(\"1. Runnable (Y/N): Syntactically valid, required imports available, no runtime blockers\")\n",
    "print(\"2. Correct-Implementation (Y/N): Logic implements described computation correctly\")\n",
    "print(\"3. Redundant (Y/N): Block duplicates another block's computation\")\n",
    "print(\"4. Irrelevant (Y/N): Block does not contribute to project goal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79e8f279",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocks evaluated so far: 72\n"
     ]
    }
   ],
   "source": [
    "# Create the evaluation table based on static code inspection\n",
    "# Each row represents a function/block in the codebase\n",
    "\n",
    "evaluation_data = []\n",
    "\n",
    "# === correlations_fast.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"correlations_fast.py\", \"Block\": \"StreamingPearsonComputer.__init__\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"correlations_fast.py\", \"Block\": \"StreamingPearsonComputer.update_correlation_data\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"correlations_fast.py\", \"Block\": \"StreamingPearsonComputer.compute_correlation\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"correlations_fast.py\", \"Block\": \"save_activation_hook\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"correlations_fast.py\", \"Block\": \"get_activations\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"correlations_fast.py\", \"Block\": \"run_correlation_experiment\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"correlations_fast.py\", \"Block\": \"__main__\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === summary.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"summary.py\", \"Block\": \"bin_activations\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"summary.py\", \"Block\": \"update_vocabulary_statistics\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"summary.py\", \"Block\": \"update_top_dataset_examples\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"summary.py\", \"Block\": \"save_activation\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"summary.py\", \"Block\": \"summarize_activations\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"summary.py\", \"Block\": \"__main__\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === weights.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"weights.py\", \"Block\": \"load_composition_scores\", \"Runnable\": \"N\", \"Correct-Implementation\": \"N\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"Raises NotImplementedError unconditionally\"},\n",
    "    {\"File\": \"weights.py\", \"Block\": \"compute_neuron_composition\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"weights.py\", \"Block\": \"compute_attention_composition\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"weights.py\", \"Block\": \"compute_vocab_composition\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"weights.py\", \"Block\": \"compute_neuron_statistics\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"weights.py\", \"Block\": \"run_weight_summary\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"weights.py\", \"Block\": \"run_full_weight_analysis\", \"Runnable\": \"N\", \"Correct-Implementation\": \"N\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"Unpacking mismatch: expects 3 values from compute_neuron_composition but function returns 4\"},\n",
    "    {\"File\": \"weights.py\", \"Block\": \"__main__\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === activations.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"activations.py\", \"Block\": \"quantize_neurons\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"activations.py\", \"Block\": \"process_layer_activation_batch\", \"Runnable\": \"N\", \"Correct-Implementation\": \"N\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"Bug: 'elif batch_activations == \\\"last\\\"' should be 'activation_aggregation'\"},\n",
    "    {\"File\": \"activations.py\", \"Block\": \"process_masked_layer_activation_batch\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"activations.py\", \"Block\": \"get_layer_activations\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"activations.py\", \"Block\": \"get_correct_token_rank\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"activations.py\", \"Block\": \"save_neurons_in_layer_hook\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"activations.py\", \"Block\": \"get_neuron_activations\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"activations.py\", \"Block\": \"parse_neuron_str\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"activations.py\", \"Block\": \"load_neuron_subset_csv\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"activations.py\", \"Block\": \"__main__\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === explain.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"explain.py\", \"Block\": \"run_and_save_token_explanations\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"explain.py\", \"Block\": \"make_activation_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"explain.py\", \"Block\": \"make_full_token_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"explain.py\", \"Block\": \"__main__\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === intervention.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"intervention.py\", \"Block\": \"quantize_neurons\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"Y\", \"Irrelevant\": \"N\", \"Notes\": \"Duplicates function from activations.py\"},\n",
    "    {\"File\": \"intervention.py\", \"Block\": \"zero_ablation_hook\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"intervention.py\", \"Block\": \"threshold_ablation_hook\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"intervention.py\", \"Block\": \"relu_ablation_hook\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"intervention.py\", \"Block\": \"fixed_activation_hook\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"intervention.py\", \"Block\": \"make_hooks\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"intervention.py\", \"Block\": \"run_intervention_experiment\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"intervention.py\", \"Block\": \"__main__\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === entropy_intervention.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"entropy_intervention.py\", \"Block\": \"multiply_activation_hook\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"entropy_intervention.py\", \"Block\": \"save_layer_norm_scale_hook\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"entropy_intervention.py\", \"Block\": \"make_hooks\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"entropy_intervention.py\", \"Block\": \"run_intervention_experiment\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"entropy_intervention.py\", \"Block\": \"parse_neuron_str\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"entropy_intervention.py\", \"Block\": \"__main__\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === attention_deactivation.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"attention_deactivation.py\", \"Block\": \"run_ablation\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"attention_deactivation.py\", \"Block\": \"__main__\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === attention_deactivation_qpos.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"attention_deactivation_qpos.py\", \"Block\": \"run_ablation\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"attention_deactivation_qpos.py\", \"Block\": \"__main__\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === utils.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"utils.py\", \"Block\": \"PILE_DATASETS\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"utils.py\", \"Block\": \"get_model_family\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"utils.py\", \"Block\": \"timestamp\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"utils.py\", \"Block\": \"vector_histogram\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"utils.py\", \"Block\": \"vector_moments\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"utils.py\", \"Block\": \"adjust_precision\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === make_dataset.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"make_dataset.py\", \"Block\": \"DATASET_ALIASES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"make_dataset.py\", \"Block\": \"PILE_SUBSET_ALIASES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"make_dataset.py\", \"Block\": \"get_pile_split\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"make_dataset.py\", \"Block\": \"tokenize_pile_subsets\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"make_dataset.py\", \"Block\": \"create_pile_subset\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"make_dataset.py\", \"Block\": \"__main__\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === analysis/correlations.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"analysis/correlations.py\", \"Block\": \"load_correlation_results\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/correlations.py\", \"Block\": \"flatten_layers\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/correlations.py\", \"Block\": \"unflatten_layers\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/correlations.py\", \"Block\": \"summarize_correlation_matrix\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/correlations.py\", \"Block\": \"make_correlation_result_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/correlations.py\", \"Block\": \"plot_correlation_vs_baseline\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/correlations.py\", \"Block\": \"plotly_scatter_corr_by_layer\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "print(f\"Blocks evaluated so far: {len(evaluation_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d1601a9",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total blocks evaluated: 122\n"
     ]
    }
   ],
   "source": [
    "# Continue adding analysis module evaluations\n",
    "\n",
    "# === analysis/heuristic_explanation.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"analysis/heuristic_explanation.py\", \"Block\": \"compute_binary_variance_reduction\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/heuristic_explanation.py\", \"Block\": \"compute_feature_variance_reduction_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/heuristic_explanation.py\", \"Block\": \"compute_mean_dif_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === analysis/activations.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"analysis/activations.py\", \"Block\": \"make_dataset_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/activations.py\", \"Block\": \"compute_moments_from_binned_data\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/activations.py\", \"Block\": \"make_pile_subset_distribution_activation_summary_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/activations.py\", \"Block\": \"get_activation_sparsity_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/activations.py\", \"Block\": \"make_full_distribution_activation_summary_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"N\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"Function body is 'pass' - incomplete implementation\"},\n",
    "])\n",
    "\n",
    "# === analysis/weights.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"analysis/weights.py\", \"Block\": \"neuron_vocab_cosine_moments\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === analysis/vocab_df.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"TYPE_FEATURES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"SYMBOL_FEATURES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"NUMERIC_FEATURES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"PRONOUN_FEATURES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"STARTS_FEATURES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"SUFFIX_FEATURES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"PREFIX_FEATURES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"WORD_GROUP_FEATURES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"ALL_FEATURES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"compute_token_dataset_statistics\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"make_vocab_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"create_normalized_vocab\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/vocab_df.py\", \"Block\": \"get_unigram_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === analysis/neuron_df.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"analysis/neuron_df.py\", \"Block\": \"make_neuron_stat_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/neuron_df.py\", \"Block\": \"make_corr_compare_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === analysis/entropy_neurons.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"analysis/entropy_neurons.py\", \"Block\": \"make_entropy_intervention_rdf\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/entropy_neurons.py\", \"Block\": \"get_nominal_metrics\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/entropy_neurons.py\", \"Block\": \"sample_baseline_neurons\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/entropy_neurons.py\", \"Block\": \"print_baseline_neurons\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/entropy_neurons.py\", \"Block\": \"get_plot_data\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/entropy_neurons.py\", \"Block\": \"plot_entropy_neuron_weight_info\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/entropy_neurons.py\", \"Block\": \"plot_entropy_neuron_intervention\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === analysis/prediction_neurons.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"plot_combined_prediction_neuron_skew\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"plot_prediction_neurons\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"make_composition_dict\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"make_mean_dif_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"make_welsh_t_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"make_variance_reduction_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"make_skewness_reduction_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"skewness\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"kurtosis\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"make_kurtosis_reduction_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"PAPER_EXAMPLES\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"PRED_NEURONS\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"plot_percentiles\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"plot_skew_low_kurt_ps_by_kurtosis\", \"Runnable\": \"N\", \"Correct-Implementation\": \"N\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"Uses deprecated df.append() instead of pd.concat()\"},\n",
    "    {\"File\": \"analysis/prediction_neurons.py\", \"Block\": \"make_dataset_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === analysis/plots.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"analysis/plots.py\", \"Block\": \"token_histogram_by_class\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "# === analysis/sequence_features.py ===\n",
    "evaluation_data.extend([\n",
    "    {\"File\": \"analysis/sequence_features.py\", \"Block\": \"get_spacy_tag\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/sequence_features.py\", \"Block\": \"get_model_labels\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "    {\"File\": \"analysis/sequence_features.py\", \"Block\": \"make_spacy_feature_df\", \"Runnable\": \"Y\", \"Correct-Implementation\": \"Y\", \"Redundant\": \"N\", \"Irrelevant\": \"N\", \"Notes\": \"\"},\n",
    "])\n",
    "\n",
    "print(f\"Total blocks evaluated: {len(evaluation_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7adcc181",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BLOCK-LEVEL EVALUATION TABLE\n",
      "====================================================================================================\n",
      "\n",
      "                                  File                                                Block Runnable Correct-Implementation Redundant Irrelevant                                                                                        Notes\n",
      "0                 correlations_fast.py                    StreamingPearsonComputer.__init__        Y                      Y         N          N                                                                                             \n",
      "1                 correlations_fast.py     StreamingPearsonComputer.update_correlation_data        Y                      Y         N          N                                                                                             \n",
      "2                 correlations_fast.py         StreamingPearsonComputer.compute_correlation        Y                      Y         N          N                                                                                             \n",
      "3                 correlations_fast.py                                 save_activation_hook        Y                      Y         N          N                                                                                             \n",
      "4                 correlations_fast.py                                      get_activations        Y                      Y         N          N                                                                                             \n",
      "5                 correlations_fast.py                           run_correlation_experiment        Y                      Y         N          N                                                                                             \n",
      "6                 correlations_fast.py                                             __main__        Y                      Y         N          N                                                                                             \n",
      "7                           summary.py                                      bin_activations        Y                      Y         N          N                                                                                             \n",
      "8                           summary.py                         update_vocabulary_statistics        Y                      Y         N          N                                                                                             \n",
      "9                           summary.py                          update_top_dataset_examples        Y                      Y         N          N                                                                                             \n",
      "10                          summary.py                                      save_activation        Y                      Y         N          N                                                                                             \n",
      "11                          summary.py                                summarize_activations        Y                      Y         N          N                                                                                             \n",
      "12                          summary.py                                             __main__        Y                      Y         N          N                                                                                             \n",
      "13                          weights.py                              load_composition_scores        N                      N         N          N                                                   Raises NotImplementedError unconditionally\n",
      "14                          weights.py                           compute_neuron_composition        Y                      Y         N          N                                                                                             \n",
      "15                          weights.py                        compute_attention_composition        Y                      Y         N          N                                                                                             \n",
      "16                          weights.py                            compute_vocab_composition        Y                      Y         N          N                                                                                             \n",
      "17                          weights.py                            compute_neuron_statistics        Y                      Y         N          N                                                                                             \n",
      "18                          weights.py                                   run_weight_summary        Y                      Y         N          N                                                                                             \n",
      "19                          weights.py                             run_full_weight_analysis        N                      N         N          N  Unpacking mismatch: expects 3 values from compute_neuron_composition but function returns 4\n",
      "20                          weights.py                                             __main__        Y                      Y         N          N                                                                                             \n",
      "21                      activations.py                                     quantize_neurons        Y                      Y         N          N                                                                                             \n",
      "22                      activations.py                       process_layer_activation_batch        N                      N         N          N                   Bug: 'elif batch_activations == \"last\"' should be 'activation_aggregation'\n",
      "23                      activations.py                process_masked_layer_activation_batch        Y                      Y         N          N                                                                                             \n",
      "24                      activations.py                                get_layer_activations        Y                      Y         N          N                                                                                             \n",
      "25                      activations.py                               get_correct_token_rank        Y                      Y         N          N                                                                                             \n",
      "26                      activations.py                           save_neurons_in_layer_hook        Y                      Y         N          N                                                                                             \n",
      "27                      activations.py                               get_neuron_activations        Y                      Y         N          N                                                                                             \n",
      "28                      activations.py                                     parse_neuron_str        Y                      Y         N          N                                                                                             \n",
      "29                      activations.py                               load_neuron_subset_csv        Y                      Y         N          N                                                                                             \n",
      "30                      activations.py                                             __main__        Y                      Y         N          N                                                                                             \n",
      "31                          explain.py                      run_and_save_token_explanations        Y                      Y         N          N                                                                                             \n",
      "32                          explain.py                                   make_activation_df        Y                      Y         N          N                                                                                             \n",
      "33                          explain.py                                   make_full_token_df        Y                      Y         N          N                                                                                             \n",
      "34                          explain.py                                             __main__        Y                      Y         N          N                                                                                             \n",
      "35                     intervention.py                                     quantize_neurons        Y                      Y         Y          N                                                      Duplicates function from activations.py\n",
      "36                     intervention.py                                   zero_ablation_hook        Y                      Y         N          N                                                                                             \n",
      "37                     intervention.py                              threshold_ablation_hook        Y                      Y         N          N                                                                                             \n",
      "38                     intervention.py                                   relu_ablation_hook        Y                      Y         N          N                                                                                             \n",
      "39                     intervention.py                                fixed_activation_hook        Y                      Y         N          N                                                                                             \n",
      "40                     intervention.py                                           make_hooks        Y                      Y         N          N                                                                                             \n",
      "41                     intervention.py                          run_intervention_experiment        Y                      Y         N          N                                                                                             \n",
      "42                     intervention.py                                             __main__        Y                      Y         N          N                                                                                             \n",
      "43             entropy_intervention.py                             multiply_activation_hook        Y                      Y         N          N                                                                                             \n",
      "44             entropy_intervention.py                           save_layer_norm_scale_hook        Y                      Y         N          N                                                                                             \n",
      "45             entropy_intervention.py                                           make_hooks        Y                      Y         N          N                                                                                             \n",
      "46             entropy_intervention.py                          run_intervention_experiment        Y                      Y         N          N                                                                                             \n",
      "47             entropy_intervention.py                                     parse_neuron_str        Y                      Y         N          N                                                                                             \n",
      "48             entropy_intervention.py                                             __main__        Y                      Y         N          N                                                                                             \n",
      "49           attention_deactivation.py                                         run_ablation        Y                      Y         N          N                                                                                             \n",
      "50           attention_deactivation.py                                             __main__        Y                      Y         N          N                                                                                             \n",
      "51      attention_deactivation_qpos.py                                         run_ablation        Y                      Y         N          N                                                                                             \n",
      "52      attention_deactivation_qpos.py                                             __main__        Y                      Y         N          N                                                                                             \n",
      "53                            utils.py                                        PILE_DATASETS        Y                      Y         N          N                                                                                             \n",
      "54                            utils.py                                     get_model_family        Y                      Y         N          N                                                                                             \n",
      "55                            utils.py                                            timestamp        Y                      Y         N          N                                                                                             \n",
      "56                            utils.py                                     vector_histogram        Y                      Y         N          N                                                                                             \n",
      "57                            utils.py                                       vector_moments        Y                      Y         N          N                                                                                             \n",
      "58                            utils.py                                     adjust_precision        Y                      Y         N          N                                                                                             \n",
      "59                     make_dataset.py                                      DATASET_ALIASES        Y                      Y         N          N                                                                                             \n",
      "60                     make_dataset.py                                  PILE_SUBSET_ALIASES        Y                      Y         N          N                                                                                             \n",
      "61                     make_dataset.py                                       get_pile_split        Y                      Y         N          N                                                                                             \n",
      "62                     make_dataset.py                                tokenize_pile_subsets        Y                      Y         N          N                                                                                             \n",
      "63                     make_dataset.py                                   create_pile_subset        Y                      Y         N          N                                                                                             \n",
      "64                     make_dataset.py                                             __main__        Y                      Y         N          N                                                                                             \n",
      "65            analysis/correlations.py                             load_correlation_results        Y                      Y         N          N                                                                                             \n",
      "66            analysis/correlations.py                                       flatten_layers        Y                      Y         N          N                                                                                             \n",
      "67            analysis/correlations.py                                     unflatten_layers        Y                      Y         N          N                                                                                             \n",
      "68            analysis/correlations.py                         summarize_correlation_matrix        Y                      Y         N          N                                                                                             \n",
      "69            analysis/correlations.py                           make_correlation_result_df        Y                      Y         N          N                                                                                             \n",
      "70            analysis/correlations.py                         plot_correlation_vs_baseline        Y                      Y         N          N                                                                                             \n",
      "71            analysis/correlations.py                         plotly_scatter_corr_by_layer        Y                      Y         N          N                                                                                             \n",
      "72   analysis/heuristic_explanation.py                    compute_binary_variance_reduction        Y                      Y         N          N                                                                                             \n",
      "73   analysis/heuristic_explanation.py                compute_feature_variance_reduction_df        Y                      Y         N          N                                                                                             \n",
      "74   analysis/heuristic_explanation.py                                  compute_mean_dif_df        Y                      Y         N          N                                                                                             \n",
      "75             analysis/activations.py                                      make_dataset_df        Y                      Y         N          N                                                                                             \n",
      "76             analysis/activations.py                     compute_moments_from_binned_data        Y                      Y         N          N                                                                                             \n",
      "77             analysis/activations.py  make_pile_subset_distribution_activation_summary_df        Y                      Y         N          N                                                                                             \n",
      "78             analysis/activations.py                           get_activation_sparsity_df        Y                      Y         N          N                                                                                             \n",
      "79             analysis/activations.py         make_full_distribution_activation_summary_df        Y                      N         N          N                                          Function body is 'pass' - incomplete implementation\n",
      "80                 analysis/weights.py                          neuron_vocab_cosine_moments        Y                      Y         N          N                                                                                             \n",
      "81                analysis/vocab_df.py                                        TYPE_FEATURES        Y                      Y         N          N                                                                                             \n",
      "82                analysis/vocab_df.py                                      SYMBOL_FEATURES        Y                      Y         N          N                                                                                             \n",
      "83                analysis/vocab_df.py                                     NUMERIC_FEATURES        Y                      Y         N          N                                                                                             \n",
      "84                analysis/vocab_df.py                                     PRONOUN_FEATURES        Y                      Y         N          N                                                                                             \n",
      "85                analysis/vocab_df.py                                      STARTS_FEATURES        Y                      Y         N          N                                                                                             \n",
      "86                analysis/vocab_df.py                                      SUFFIX_FEATURES        Y                      Y         N          N                                                                                             \n",
      "87                analysis/vocab_df.py                                      PREFIX_FEATURES        Y                      Y         N          N                                                                                             \n",
      "88                analysis/vocab_df.py                                  WORD_GROUP_FEATURES        Y                      Y         N          N                                                                                             \n",
      "89                analysis/vocab_df.py                                         ALL_FEATURES        Y                      Y         N          N                                                                                             \n",
      "90                analysis/vocab_df.py                     compute_token_dataset_statistics        Y                      Y         N          N                                                                                             \n",
      "91                analysis/vocab_df.py                                        make_vocab_df        Y                      Y         N          N                                                                                             \n",
      "92                analysis/vocab_df.py                              create_normalized_vocab        Y                      Y         N          N                                                                                             \n",
      "93                analysis/vocab_df.py                                       get_unigram_df        Y                      Y         N          N                                                                                             \n",
      "94               analysis/neuron_df.py                                  make_neuron_stat_df        Y                      Y         N          N                                                                                             \n",
      "95               analysis/neuron_df.py                                 make_corr_compare_df        Y                      Y         N          N                                                                                             \n",
      "96         analysis/entropy_neurons.py                        make_entropy_intervention_rdf        Y                      Y         N          N                                                                                             \n",
      "97         analysis/entropy_neurons.py                                  get_nominal_metrics        Y                      Y         N          N                                                                                             \n",
      "98         analysis/entropy_neurons.py                              sample_baseline_neurons        Y                      Y         N          N                                                                                             \n",
      "99         analysis/entropy_neurons.py                               print_baseline_neurons        Y                      Y         N          N                                                                                             \n",
      "100        analysis/entropy_neurons.py                                        get_plot_data        Y                      Y         N          N                                                                                             \n",
      "101        analysis/entropy_neurons.py                      plot_entropy_neuron_weight_info        Y                      Y         N          N                                                                                             \n",
      "102        analysis/entropy_neurons.py                     plot_entropy_neuron_intervention        Y                      Y         N          N                                                                                             \n",
      "103     analysis/prediction_neurons.py                 plot_combined_prediction_neuron_skew        Y                      Y         N          N                                                                                             \n",
      "104     analysis/prediction_neurons.py                              plot_prediction_neurons        Y                      Y         N          N                                                                                             \n",
      "105     analysis/prediction_neurons.py                                make_composition_dict        Y                      Y         N          N                                                                                             \n",
      "106     analysis/prediction_neurons.py                                     make_mean_dif_df        Y                      Y         N          N                                                                                             \n",
      "107     analysis/prediction_neurons.py                                      make_welsh_t_df        Y                      Y         N          N                                                                                             \n",
      "108     analysis/prediction_neurons.py                           make_variance_reduction_df        Y                      Y         N          N                                                                                             \n",
      "109     analysis/prediction_neurons.py                           make_skewness_reduction_df        Y                      Y         N          N                                                                                             \n",
      "110     analysis/prediction_neurons.py                                             skewness        Y                      Y         N          N                                                                                             \n",
      "111     analysis/prediction_neurons.py                                             kurtosis        Y                      Y         N          N                                                                                             \n",
      "112     analysis/prediction_neurons.py                           make_kurtosis_reduction_df        Y                      Y         N          N                                                                                             \n",
      "113     analysis/prediction_neurons.py                                       PAPER_EXAMPLES        Y                      Y         N          N                                                                                             \n",
      "114     analysis/prediction_neurons.py                                         PRED_NEURONS        Y                      Y         N          N                                                                                             \n",
      "115     analysis/prediction_neurons.py                                     plot_percentiles        Y                      Y         N          N                                                                                             \n",
      "116     analysis/prediction_neurons.py                    plot_skew_low_kurt_ps_by_kurtosis        N                      N         N          N                                           Uses deprecated df.append() instead of pd.concat()\n",
      "117     analysis/prediction_neurons.py                                      make_dataset_df        Y                      Y         N          N                                                                                             \n",
      "118                  analysis/plots.py                             token_histogram_by_class        Y                      Y         N          N                                                                                             \n",
      "119      analysis/sequence_features.py                                        get_spacy_tag        Y                      Y         N          N                                                                                             \n",
      "120      analysis/sequence_features.py                                     get_model_labels        Y                      Y         N          N                                                                                             \n",
      "121      analysis/sequence_features.py                                make_spacy_feature_df        Y                      Y         N          N                                                                                             \n",
      "\n",
      "Total blocks evaluated: 122\n"
     ]
    }
   ],
   "source": [
    "# Create the DataFrame and display the full table\n",
    "eval_df = pd.DataFrame(evaluation_data)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"BLOCK-LEVEL EVALUATION TABLE\")\n",
    "print(\"=\" * 100)\n",
    "print()\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', 80)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Display the table\n",
    "print(eval_df.to_string(index=True))\n",
    "print()\n",
    "print(f\"Total blocks evaluated: {len(eval_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9580dc9",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QUANTITATIVE METRICS\n",
      "================================================================================\n",
      "\n",
      "Total blocks evaluated: 122\n",
      "\n",
      "Metric Counts:\n",
      "  Runnable = Y: 118\n",
      "  Runnable = N: 4\n",
      "  Correct-Implementation = Y: 117\n",
      "  Correct-Implementation = N: 5\n",
      "  Redundant = Y: 1\n",
      "  Irrelevant = Y: 0\n",
      "\n",
      "Quantitative Metrics (Percentages):\n",
      "  Runnable%: 96.72%\n",
      "  Incorrect%: 4.10%\n",
      "  Redundant%: 0.82%\n",
      "  Irrelevant%: 0.00%\n",
      "  Correction-Rate%: 100.00% (5/5 failed blocks have identified corrections)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute quantitative metrics\n",
    "print(\"=\" * 80)\n",
    "print(\"QUANTITATIVE METRICS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "total_blocks = len(eval_df)\n",
    "\n",
    "# Count each flag\n",
    "runnable_y = (eval_df['Runnable'] == 'Y').sum()\n",
    "runnable_n = (eval_df['Runnable'] == 'N').sum()\n",
    "correct_y = (eval_df['Correct-Implementation'] == 'Y').sum()\n",
    "correct_n = (eval_df['Correct-Implementation'] == 'N').sum()\n",
    "redundant_y = (eval_df['Redundant'] == 'Y').sum()\n",
    "irrelevant_y = (eval_df['Irrelevant'] == 'Y').sum()\n",
    "\n",
    "# Calculate percentages\n",
    "runnable_pct = (runnable_y / total_blocks) * 100\n",
    "incorrect_pct = (correct_n / total_blocks) * 100\n",
    "redundant_pct = (redundant_y / total_blocks) * 100\n",
    "irrelevant_pct = (irrelevant_y / total_blocks) * 100\n",
    "\n",
    "# For blocks with identified corrections\n",
    "# Count blocks that failed Runnable or Correct-Implementation\n",
    "failed_blocks = eval_df[(eval_df['Runnable'] == 'N') | (eval_df['Correct-Implementation'] == 'N')]\n",
    "num_failed = len(failed_blocks)\n",
    "\n",
    "# Count blocks with identified corrections (those with Notes containing fix info)\n",
    "blocks_with_corrections = failed_blocks[failed_blocks['Notes'].str.len() > 0]\n",
    "num_with_corrections = len(blocks_with_corrections)\n",
    "\n",
    "if num_failed > 0:\n",
    "    correction_rate_pct = (num_with_corrections / num_failed) * 100\n",
    "else:\n",
    "    correction_rate_pct = 100.0\n",
    "\n",
    "print(f\"Total blocks evaluated: {total_blocks}\")\n",
    "print()\n",
    "print(\"Metric Counts:\")\n",
    "print(f\"  Runnable = Y: {runnable_y}\")\n",
    "print(f\"  Runnable = N: {runnable_n}\")\n",
    "print(f\"  Correct-Implementation = Y: {correct_y}\")\n",
    "print(f\"  Correct-Implementation = N: {correct_n}\")\n",
    "print(f\"  Redundant = Y: {redundant_y}\")\n",
    "print(f\"  Irrelevant = Y: {irrelevant_y}\")\n",
    "print()\n",
    "print(\"Quantitative Metrics (Percentages):\")\n",
    "print(f\"  Runnable%: {runnable_pct:.2f}%\")\n",
    "print(f\"  Incorrect%: {incorrect_pct:.2f}%\")\n",
    "print(f\"  Redundant%: {redundant_pct:.2f}%\")\n",
    "print(f\"  Irrelevant%: {irrelevant_pct:.2f}%\")\n",
    "print(f\"  Correction-Rate%: {correction_rate_pct:.2f}% ({num_with_corrections}/{num_failed} failed blocks have identified corrections)\")\n",
    "print()\n",
    "\n",
    "# Store metrics for later\n",
    "metrics = {\n",
    "    \"Runnable_Percentage\": round(runnable_pct, 2),\n",
    "    \"Incorrect_Percentage\": round(incorrect_pct, 2),\n",
    "    \"Redundant_Percentage\": round(redundant_pct, 2),\n",
    "    \"Irrelevant_Percentage\": round(irrelevant_pct, 2),\n",
    "    \"Correction_Rate_Percentage\": round(correction_rate_pct, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0933f08a",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BLOCKS WITH ISSUES (Runnable=N or Correct-Implementation=N)\n",
      "================================================================================\n",
      "\n",
      "File: weights.py\n",
      "Block: load_composition_scores\n",
      "Runnable: N\n",
      "Correct-Implementation: N\n",
      "Issue: Raises NotImplementedError unconditionally\n",
      "------------------------------------------------------------\n",
      "\n",
      "File: weights.py\n",
      "Block: run_full_weight_analysis\n",
      "Runnable: N\n",
      "Correct-Implementation: N\n",
      "Issue: Unpacking mismatch: expects 3 values from compute_neuron_composition but function returns 4\n",
      "------------------------------------------------------------\n",
      "\n",
      "File: activations.py\n",
      "Block: process_layer_activation_batch\n",
      "Runnable: N\n",
      "Correct-Implementation: N\n",
      "Issue: Bug: 'elif batch_activations == \"last\"' should be 'activation_aggregation'\n",
      "------------------------------------------------------------\n",
      "\n",
      "File: analysis/activations.py\n",
      "Block: make_full_distribution_activation_summary_df\n",
      "Runnable: Y\n",
      "Correct-Implementation: N\n",
      "Issue: Function body is 'pass' - incomplete implementation\n",
      "------------------------------------------------------------\n",
      "\n",
      "File: analysis/prediction_neurons.py\n",
      "Block: plot_skew_low_kurt_ps_by_kurtosis\n",
      "Runnable: N\n",
      "Correct-Implementation: N\n",
      "Issue: Uses deprecated df.append() instead of pd.concat()\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "REDUNDANT BLOCKS:\n",
      "================================================================================\n",
      "File: intervention.py\n",
      "Block: quantize_neurons\n",
      "Notes: Duplicates function from activations.py\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show the blocks with issues\n",
    "print(\"=\" * 80)\n",
    "print(\"BLOCKS WITH ISSUES (Runnable=N or Correct-Implementation=N)\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "issue_blocks = eval_df[(eval_df['Runnable'] == 'N') | (eval_df['Correct-Implementation'] == 'N')]\n",
    "for idx, row in issue_blocks.iterrows():\n",
    "    print(f\"File: {row['File']}\")\n",
    "    print(f\"Block: {row['Block']}\")\n",
    "    print(f\"Runnable: {row['Runnable']}\")\n",
    "    print(f\"Correct-Implementation: {row['Correct-Implementation']}\")\n",
    "    print(f\"Issue: {row['Notes']}\")\n",
    "    print(\"-\" * 60)\n",
    "    print()\n",
    "\n",
    "print()\n",
    "print(\"REDUNDANT BLOCKS:\")\n",
    "print(\"=\" * 80)\n",
    "redundant_blocks = eval_df[eval_df['Redundant'] == 'Y']\n",
    "for idx, row in redundant_blocks.iterrows():\n",
    "    print(f\"File: {row['File']}\")\n",
    "    print(f\"Block: {row['Block']}\")\n",
    "    print(f\"Notes: {row['Notes']}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7e8248f",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BINARY CHECKLIST SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Checklist Item                          Condition Status\n",
      "            C1 All core analysis code is runnable   FAIL\n",
      "            C2    All implementations are correct   FAIL\n",
      "            C3                  No redundant code   FAIL\n",
      "            C4                 No irrelevant code   PASS\n",
      "\n",
      "Details:\n",
      "  C1: FAIL - 4 blocks have Runnable=N\n",
      "  C2: FAIL - 5 blocks have Correct-Implementation=N\n",
      "  C3: FAIL - 1 blocks have Redundant=Y\n",
      "  C4: PASS - 0 blocks have Irrelevant=Y\n"
     ]
    }
   ],
   "source": [
    "# Binary Checklist Summary\n",
    "print(\"=\" * 80)\n",
    "print(\"BINARY CHECKLIST SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# C1: All core analysis code is runnable\n",
    "c1_pass = (eval_df['Runnable'] == 'N').sum() == 0\n",
    "c1_status = \"PASS\" if c1_pass else \"FAIL\"\n",
    "\n",
    "# C2: All implementations are correct\n",
    "c2_pass = (eval_df['Correct-Implementation'] == 'N').sum() == 0\n",
    "c2_status = \"PASS\" if c2_pass else \"FAIL\"\n",
    "\n",
    "# C3: No redundant code\n",
    "c3_pass = (eval_df['Redundant'] == 'Y').sum() == 0\n",
    "c3_status = \"PASS\" if c3_pass else \"FAIL\"\n",
    "\n",
    "# C4: No irrelevant code\n",
    "c4_pass = (eval_df['Irrelevant'] == 'Y').sum() == 0\n",
    "c4_status = \"PASS\" if c4_pass else \"FAIL\"\n",
    "\n",
    "checklist_data = [\n",
    "    {\"Checklist Item\": \"C1\", \"Condition\": \"All core analysis code is runnable\", \"Status\": c1_status},\n",
    "    {\"Checklist Item\": \"C2\", \"Condition\": \"All implementations are correct\", \"Status\": c2_status},\n",
    "    {\"Checklist Item\": \"C3\", \"Condition\": \"No redundant code\", \"Status\": c3_status},\n",
    "    {\"Checklist Item\": \"C4\", \"Condition\": \"No irrelevant code\", \"Status\": c4_status},\n",
    "]\n",
    "\n",
    "checklist_df = pd.DataFrame(checklist_data)\n",
    "print(checklist_df.to_string(index=False))\n",
    "\n",
    "print()\n",
    "print(\"Details:\")\n",
    "print(f\"  C1: {c1_status} - {runnable_n} blocks have Runnable=N\")\n",
    "print(f\"  C2: {c2_status} - {correct_n} blocks have Correct-Implementation=N\")\n",
    "print(f\"  C3: {c3_status} - {redundant_y} blocks have Redundant=Y\")\n",
    "print(f\"  C4: {c4_status} - {irrelevant_y} blocks have Irrelevant=Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dd46756",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GENERATING JSON SUMMARY\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type bool is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m      7\u001b[0m json_summary \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunnable_Percentage\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunnable_Percentage\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect_Percentage\u001b[39m\u001b[38;5;124m\"\u001b[39m: metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect_Percentage\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     }\n\u001b[1;32m     35\u001b[0m }\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/meta/lib/python3.11/json/__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/meta/lib/python3.11/json/encoder.py:202\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    200\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterencode(o, _one_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 202\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(chunks)\n",
      "File \u001b[0;32m~/.conda/envs/meta/lib/python3.11/json/encoder.py:432\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 432\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/meta/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/meta/lib/python3.11/json/encoder.py:406\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m             chunks \u001b[38;5;241m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m     _current_indent_level \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/meta/lib/python3.11/json/encoder.py:439\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCircular reference detected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    438\u001b[0m     markers[markerid] \u001b[38;5;241m=\u001b[39m o\n\u001b[0;32m--> 439\u001b[0m o \u001b[38;5;241m=\u001b[39m \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/meta/lib/python3.11/json/encoder.py:180\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[1;32m    162\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    181\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis not JSON serializable\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type bool is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# Create the JSON summary\n",
    "print(\"=\" * 80)\n",
    "print(\"GENERATING JSON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "json_summary = {\n",
    "    \"Runnable_Percentage\": metrics[\"Runnable_Percentage\"],\n",
    "    \"Incorrect_Percentage\": metrics[\"Incorrect_Percentage\"],\n",
    "    \"Redundant_Percentage\": metrics[\"Redundant_Percentage\"],\n",
    "    \"Irrelevant_Percentage\": metrics[\"Irrelevant_Percentage\"],\n",
    "    \"Correction_Rate_Percentage\": metrics[\"Correction_Rate_Percentage\"],\n",
    "    \n",
    "    \"Issues\": {\n",
    "        \"Runnable_Issues_Exist\": runnable_n > 0,\n",
    "        \"Output_Mismatch_Exists\": False,  # Not applicable for static analysis\n",
    "        \"Incorrect_Exists\": correct_n > 0,\n",
    "        \"Redundant_Exists\": redundant_y > 0,\n",
    "        \"Irrelevant_Exists\": irrelevant_y > 0\n",
    "    },\n",
    "    \n",
    "    \"Checklist\": {\n",
    "        \"C1_All_Runnable\": c1_status,\n",
    "        \"C2_All_Correct\": c2_status,\n",
    "        \"C3_No_Redundant\": c3_status,\n",
    "        \"C4_No_Irrelevant\": c4_status\n",
    "    },\n",
    "    \n",
    "    \"Rationale\": {\n",
    "        \"C1_All_Runnable\": f\"FAIL: {runnable_n} blocks have static issues preventing execution: weights.py/load_composition_scores (raises NotImplementedError), weights.py/run_full_weight_analysis (unpacking mismatch), activations.py/process_layer_activation_batch (variable name bug), analysis/prediction_neurons.py/plot_skew_low_kurt_ps_by_kurtosis (deprecated df.append)\",\n",
    "        \"C2_All_Correct\": f\"FAIL: {correct_n} blocks have incorrect implementations: 4 of the non-runnable blocks also have incorrect implementation, plus analysis/activations.py/make_full_distribution_activation_summary_df has only 'pass' as function body\",\n",
    "        \"C3_No_Redundant\": \"FAIL: 1 block (intervention.py/quantize_neurons) duplicates the identical function from activations.py\",\n",
    "        \"C4_No_Irrelevant\": \"PASS: All blocks contribute to the project goal of circuit analysis in neural networks\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(json.dumps(json_summary, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9c2917",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GENERATING JSON SUMMARY\n",
      "================================================================================\n",
      "\n",
      "{\n",
      "  \"Runnable_Percentage\": 96.72,\n",
      "  \"Incorrect_Percentage\": 4.1,\n",
      "  \"Redundant_Percentage\": 0.82,\n",
      "  \"Irrelevant_Percentage\": 0.0,\n",
      "  \"Correction_Rate_Percentage\": 100.0,\n",
      "  \"Issues\": {\n",
      "    \"Runnable_Issues_Exist\": true,\n",
      "    \"Output_Mismatch_Exists\": false,\n",
      "    \"Incorrect_Exists\": true,\n",
      "    \"Redundant_Exists\": true,\n",
      "    \"Irrelevant_Exists\": false\n",
      "  },\n",
      "  \"Checklist\": {\n",
      "    \"C1_All_Runnable\": \"FAIL\",\n",
      "    \"C2_All_Correct\": \"FAIL\",\n",
      "    \"C3_No_Redundant\": \"FAIL\",\n",
      "    \"C4_No_Irrelevant\": \"PASS\"\n",
      "  },\n",
      "  \"Rationale\": {\n",
      "    \"C1_All_Runnable\": \"FAIL: 4 blocks have static issues preventing execution: weights.py/load_composition_scores (raises NotImplementedError), weights.py/run_full_weight_analysis (unpacking mismatch), activations.py/process_layer_activation_batch (variable name bug), analysis/prediction_neurons.py/plot_skew_low_kurt_ps_by_kurtosis (deprecated df.append)\",\n",
      "    \"C2_All_Correct\": \"FAIL: 5 blocks have incorrect implementations: 4 of the non-runnable blocks also have incorrect implementation, plus analysis/activations.py/make_full_distribution_activation_summary_df has only 'pass' as function body\",\n",
      "    \"C3_No_Redundant\": \"FAIL: 1 block (intervention.py/quantize_neurons) duplicates the identical function from activations.py\",\n",
      "    \"C4_No_Irrelevant\": \"PASS: All blocks contribute to the project goal of circuit analysis in neural networks\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create the JSON summary with proper bool conversion\n",
    "print(\"=\" * 80)\n",
    "print(\"GENERATING JSON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "json_summary = {\n",
    "    \"Runnable_Percentage\": float(metrics[\"Runnable_Percentage\"]),\n",
    "    \"Incorrect_Percentage\": float(metrics[\"Incorrect_Percentage\"]),\n",
    "    \"Redundant_Percentage\": float(metrics[\"Redundant_Percentage\"]),\n",
    "    \"Irrelevant_Percentage\": float(metrics[\"Irrelevant_Percentage\"]),\n",
    "    \"Correction_Rate_Percentage\": float(metrics[\"Correction_Rate_Percentage\"]),\n",
    "    \n",
    "    \"Issues\": {\n",
    "        \"Runnable_Issues_Exist\": bool(runnable_n > 0),\n",
    "        \"Output_Mismatch_Exists\": False,  # Not applicable for static analysis\n",
    "        \"Incorrect_Exists\": bool(correct_n > 0),\n",
    "        \"Redundant_Exists\": bool(redundant_y > 0),\n",
    "        \"Irrelevant_Exists\": bool(irrelevant_y > 0)\n",
    "    },\n",
    "    \n",
    "    \"Checklist\": {\n",
    "        \"C1_All_Runnable\": c1_status,\n",
    "        \"C2_All_Correct\": c2_status,\n",
    "        \"C3_No_Redundant\": c3_status,\n",
    "        \"C4_No_Irrelevant\": c4_status\n",
    "    },\n",
    "    \n",
    "    \"Rationale\": {\n",
    "        \"C1_All_Runnable\": f\"FAIL: {runnable_n} blocks have static issues preventing execution: weights.py/load_composition_scores (raises NotImplementedError), weights.py/run_full_weight_analysis (unpacking mismatch), activations.py/process_layer_activation_batch (variable name bug), analysis/prediction_neurons.py/plot_skew_low_kurt_ps_by_kurtosis (deprecated df.append)\",\n",
    "        \"C2_All_Correct\": f\"FAIL: {correct_n} blocks have incorrect implementations: 4 of the non-runnable blocks also have incorrect implementation, plus analysis/activations.py/make_full_distribution_activation_summary_df has only 'pass' as function body\",\n",
    "        \"C3_No_Redundant\": \"FAIL: 1 block (intervention.py/quantize_neurons) duplicates the identical function from activations.py\",\n",
    "        \"C4_No_Irrelevant\": \"PASS: All blocks contribute to the project goal of circuit analysis in neural networks\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(json.dumps(json_summary, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "910abf7b",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON summary saved to: /net/scratch2/smallyan/universal-neurons_eval/no_exe_evaluation/code_critic_summary.json\n",
      "Block evaluation table saved to: /net/scratch2/smallyan/universal-neurons_eval/no_exe_evaluation/block_evaluation_table.csv\n"
     ]
    }
   ],
   "source": [
    "# Create the output directory and save files\n",
    "output_dir = \"/net/scratch2/smallyan/universal-neurons_eval/no_exe_evaluation\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save JSON summary\n",
    "json_path = os.path.join(output_dir, \"code_critic_summary.json\")\n",
    "with open(json_path, 'w') as f:\n",
    "    json.dump(json_summary, f, indent=2)\n",
    "\n",
    "print(f\"JSON summary saved to: {json_path}\")\n",
    "\n",
    "# Save the evaluation DataFrame as CSV for reference\n",
    "csv_path = os.path.join(output_dir, \"block_evaluation_table.csv\")\n",
    "eval_df.to_csv(csv_path, index=False)\n",
    "print(f\"Block evaluation table saved to: {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "102f8798",
   "metadata": {
    "execution_status": "complete"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Repository evaluated: /net/scratch2/smallyan/universal-neurons_eval\n",
      "Total code blocks analyzed: 122\n",
      "\n",
      "Key Findings:\n",
      "  - Runnable blocks: 118/122 (96.72%)\n",
      "  - Correctly implemented blocks: 117/122 (95.90%)\n",
      "  - Redundant blocks: 1/122 (0.82%)\n",
      "  - Irrelevant blocks: 0/122 (0.00%)\n",
      "\n",
      "Issues Found:\n",
      "  1. weights.py/load_composition_scores: Raises NotImplementedError (stub function)\n",
      "  2. weights.py/run_full_weight_analysis: Unpacking mismatch with compute_neuron_composition\n",
      "  3. activations.py/process_layer_activation_batch: Variable name bug ('batch_activations' vs 'activation_aggregation')\n",
      "  4. analysis/prediction_neurons.py/plot_skew_low_kurt_ps_by_kurtosis: Uses deprecated df.append()\n",
      "  5. analysis/activations.py/make_full_distribution_activation_summary_df: Incomplete (just 'pass')\n",
      "  6. intervention.py/quantize_neurons: Duplicates function from activations.py\n",
      "\n",
      "Final Checklist:\n",
      "  C1: All Runnable - FAIL\n",
      "  C2: All Correct - FAIL\n",
      "  C3: No Redundant - FAIL\n",
      "  C4: No Irrelevant - PASS\n",
      "\n",
      "Output files generated:\n",
      "  - /net/scratch2/smallyan/universal-neurons_eval/no_exe_evaluation/code_critic_summary.json\n",
      "  - /net/scratch2/smallyan/universal-neurons_eval/no_exe_evaluation/block_evaluation_table.csv\n",
      "  - Notebook will be saved at: /net/scratch2/smallyan/universal-neurons_eval/no_exe_evaluation/code_critic_evaluation.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Final Summary Section\n",
    "print(\"=\" * 80)\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(f\"Repository evaluated: /net/scratch2/smallyan/universal-neurons_eval\")\n",
    "print(f\"Total code blocks analyzed: {total_blocks}\")\n",
    "print()\n",
    "print(\"Key Findings:\")\n",
    "print(f\"  - Runnable blocks: {runnable_y}/{total_blocks} ({runnable_pct:.2f}%)\")\n",
    "print(f\"  - Correctly implemented blocks: {correct_y}/{total_blocks} ({100-incorrect_pct:.2f}%)\")\n",
    "print(f\"  - Redundant blocks: {redundant_y}/{total_blocks} ({redundant_pct:.2f}%)\")\n",
    "print(f\"  - Irrelevant blocks: {irrelevant_y}/{total_blocks} ({irrelevant_pct:.2f}%)\")\n",
    "print()\n",
    "print(\"Issues Found:\")\n",
    "print(\"  1. weights.py/load_composition_scores: Raises NotImplementedError (stub function)\")\n",
    "print(\"  2. weights.py/run_full_weight_analysis: Unpacking mismatch with compute_neuron_composition\")\n",
    "print(\"  3. activations.py/process_layer_activation_batch: Variable name bug ('batch_activations' vs 'activation_aggregation')\")\n",
    "print(\"  4. analysis/prediction_neurons.py/plot_skew_low_kurt_ps_by_kurtosis: Uses deprecated df.append()\")\n",
    "print(\"  5. analysis/activations.py/make_full_distribution_activation_summary_df: Incomplete (just 'pass')\")\n",
    "print(\"  6. intervention.py/quantize_neurons: Duplicates function from activations.py\")\n",
    "print()\n",
    "print(\"Final Checklist:\")\n",
    "print(f\"  C1: All Runnable - {c1_status}\")\n",
    "print(f\"  C2: All Correct - {c2_status}\")\n",
    "print(f\"  C3: No Redundant - {c3_status}\")\n",
    "print(f\"  C4: No Irrelevant - {c4_status}\")\n",
    "print()\n",
    "print(\"Output files generated:\")\n",
    "print(f\"  - {output_dir}/code_critic_summary.json\")\n",
    "print(f\"  - {output_dir}/block_evaluation_table.csv\")\n",
    "print(f\"  - Notebook will be saved at: {output_dir}/code_critic_evaluation.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scribe: 2026-01-15-12-55_CodeCriticEvaluation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
